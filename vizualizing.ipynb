{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3124704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)   # mostra todas as colunas\n",
    "pd.set_option(\"display.width\", None)         # evita quebra de linha\n",
    "pd.set_option(\"display.max_rows\", None)      # idem para linhas, se quiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb28104a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Status❔</th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>Inference Time(ms/im)</th>\n",
       "      <th>Avarage Processing Time (ms/im)</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Throughput (img/s)</th>\n",
       "      <th>cpu_proc_avg (%)</th>\n",
       "      <th>ram_proc_mb (MB)</th>\n",
       "      <th>gpu_avg (%)</th>\n",
       "      <th>power_avg (W)</th>\n",
       "      <th>ram_total_mb (MB)</th>\n",
       "      <th>metrics/mAP50-95(M)</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/precision(M)</th>\n",
       "      <th>metrics/recall(M)</th>\n",
       "      <th>metrics/mAP50(M)</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TensorRT FP32</td>\n",
       "      <td>✅</td>\n",
       "      <td>40.5</td>\n",
       "      <td>10.84</td>\n",
       "      <td>22.40</td>\n",
       "      <td>44.65</td>\n",
       "      <td>43.83</td>\n",
       "      <td>39.63</td>\n",
       "      <td>2394.6</td>\n",
       "      <td>54.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12078.0</td>\n",
       "      <td>0.5999</td>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.9239</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>JetsonOrin16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TensorRT FP16</td>\n",
       "      <td>✅</td>\n",
       "      <td>40.5</td>\n",
       "      <td>10.83</td>\n",
       "      <td>22.16</td>\n",
       "      <td>45.13</td>\n",
       "      <td>44.29</td>\n",
       "      <td>59.28</td>\n",
       "      <td>2454.8</td>\n",
       "      <td>57.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12472.8</td>\n",
       "      <td>0.5999</td>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.9239</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>JetsonOrin16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ONNX</td>\n",
       "      <td>❌ UnboundLocalError</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>local variable 'fmt' referenced before assignment</td>\n",
       "      <td>JetsonOrin16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PyTorch</td>\n",
       "      <td>❌ UnboundLocalError</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>local variable 'fmt' referenced before assignment</td>\n",
       "      <td>JetsonOrin16gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Format              Status❔  Size (MB)  Inference Time(ms/im)  \\\n",
       "0  TensorRT FP32                    ✅       40.5                  10.84   \n",
       "1  TensorRT FP16                    ✅       40.5                  10.83   \n",
       "2           ONNX  ❌ UnboundLocalError        NaN                    NaN   \n",
       "3        PyTorch  ❌ UnboundLocalError        NaN                    NaN   \n",
       "\n",
       "   Avarage Processing Time (ms/im)    FPS  Throughput (img/s)  \\\n",
       "0                            22.40  44.65               43.83   \n",
       "1                            22.16  45.13               44.29   \n",
       "2                              NaN    NaN                 NaN   \n",
       "3                              NaN    NaN                 NaN   \n",
       "\n",
       "   cpu_proc_avg (%)  ram_proc_mb (MB)  gpu_avg (%)  power_avg (W)  \\\n",
       "0             39.63            2394.6        54.27            0.0   \n",
       "1             59.28            2454.8        57.27            0.0   \n",
       "2               NaN               NaN          NaN            NaN   \n",
       "3               NaN               NaN          NaN            NaN   \n",
       "\n",
       "   ram_total_mb (MB)  metrics/mAP50-95(M)  metrics/precision(B)  \\\n",
       "0            12078.0               0.5999                0.9547   \n",
       "1            12472.8               0.5999                0.9547   \n",
       "2                NaN                  NaN                   NaN   \n",
       "3                NaN                  NaN                   NaN   \n",
       "\n",
       "   metrics/recall(B)  metrics/mAP50(B)  metrics/precision(M)  \\\n",
       "0             0.9521            0.9884                0.9239   \n",
       "1             0.9521            0.9884                0.9239   \n",
       "2                NaN               NaN                   NaN   \n",
       "3                NaN               NaN                   NaN   \n",
       "\n",
       "   metrics/recall(M)                                   metrics/mAP50(M)  \\\n",
       "0              0.898                                             0.9437   \n",
       "1              0.898                                             0.9437   \n",
       "2                NaN  local variable 'fmt' referenced before assignment   \n",
       "3                NaN  local variable 'fmt' referenced before assignment   \n",
       "\n",
       "           device  \n",
       "0  JetsonOrin16gb  \n",
       "1  JetsonOrin16gb  \n",
       "2  JetsonOrin16gb  \n",
       "3  JetsonOrin16gb  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bench_results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05998b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (8 CPUs, 15.3 GB RAM, 36.0/115.4 GB disk)\n",
      "\n",
      "Benchmarks complete for models/land-seg.pt on dataset/landslide_dataset_1000/data.yml at imgsz=512 (8.57s)\n",
      "Benchmarks legend:  - ✅ Success  - ❎ Export passed but validation failed  - ❌️ Export failed\n",
      "    Format Status❔  Size (MB)  metrics/mAP50-95(M)  Inference time (ms/im)    FPS\n",
      "0  PyTorch       ✅       19.6               0.6295                   24.78  40.35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.utils.benchmarks import benchmark\n",
    "from ultralytics import YOLO\n",
    "\n",
    "results_ultr = benchmark(model=f\"models/land-seg.pt\", data=\"dataset/landslide_dataset_1000/data.yml\", imgsz=512, format='-', device =0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (8 CPUs, 15.3 GB RAM, 36.0/115.4 GB disk)\n",
      "\n",
      "Benchmarks complete for models/land-seg.pt on dataset/landslide_dataset_1000/data.yml at imgsz=512 (284.69s)\n",
      "Benchmarks legend:  - ✅ Success  - ❎ Export passed but validation failed  - ❌️ Export failed\n",
      "     Format Status❔  Size (MB)  metrics/mAP50-95(M)  Inference time (ms/im)    FPS\n",
      "0  TensorRT       ✅       41.0               0.5998                   27.15  36.83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_ultr = benchmark(model=f\"models/land-seg.pt\", data=\"dataset/landslide_dataset_1000/data.yml\", imgsz=512, format='engine', device =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e16e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (8 CPUs, 15.3 GB RAM, 36.0/115.4 GB disk)\n",
      "\n",
      "Benchmarks complete for models/land-seg.pt on dataset/landslide_dataset_1000/data.yml at imgsz=512 (43.07s)\n",
      "Benchmarks legend:  - ✅ Success  - ❎ Export passed but validation failed  - ❌️ Export failed\n",
      "  Format Status❔  Size (MB)  metrics/mAP50-95(M)  Inference time (ms/im)  FPS\n",
      "0   ONNX       ✅       38.6               0.5998                  153.89  6.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_ultr = benchmark(model=f\"models/land-seg.pt\", data=\"dataset/landslide_dataset_1000/data.yml\", imgsz=512, format='onnx', device =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "770be9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.161 🚀 Python-3.10.12 torch-2.5.0a0+872d972e41.nv24.08 CUDA:0 (Orin, 15656MiB)\n",
      "YOLO11s-seg summary (fused): 113 layers, 10,067,203 parameters, 0 gradients, 35.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'models/land-seg.pt' with input shape (1, 3, 512, 512) BCHW and output shape(s) ((1, 300, 38), (1, 32, 128, 128)) (19.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.58...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 3.9s, saved as 'models/land-seg.onnx' (38.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.3.0...\n",
      "[09/12/2025-06:52:45] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 1516, GPU 9207 (MiB)\n",
      "[09/12/2025-06:52:46] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +926, GPU +711, now: CPU 2442, GPU 9918 (MiB)\n",
      "[09/12/2025-06:52:46] [TRT] [I] ----------------------------------------------------------------\n",
      "[09/12/2025-06:52:46] [TRT] [I] Input filename:   models/land-seg.onnx\n",
      "[09/12/2025-06:52:46] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[09/12/2025-06:52:46] [TRT] [I] Opset version:    19\n",
      "[09/12/2025-06:52:46] [TRT] [I] Producer name:    pytorch\n",
      "[09/12/2025-06:52:46] [TRT] [I] Producer version: 2.5.0\n",
      "[09/12/2025-06:52:46] [TRT] [I] Domain:           \n",
      "[09/12/2025-06:52:46] [TRT] [I] Model version:    0\n",
      "[09/12/2025-06:52:46] [TRT] [I] Doc string:       \n",
      "[09/12/2025-06:52:46] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 512, 512) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 300, 38) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(1, 32, 128, 128) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as models/land-seg.engine\n",
      "[09/12/2025-06:52:46] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[09/12/2025-06:58:46] [TRT] [I] Detected 1 inputs and 2 output network tensors.\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Host Persistent Memory: 587504\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Device Persistent Memory: 69120\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Scratch Memory: 1179648\n",
      "[09/12/2025-06:58:51] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 193 steps to complete.\n",
      "[09/12/2025-06:58:51] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 26.6743ms to assign 13 blocks to 193 nodes requiring 13108224 bytes.\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Activation Memory: 13107200\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Weights Memory: 20248896\n",
      "[09/12/2025-06:58:52] [TRT] [I] Engine generation completed in 365.087 seconds.\n",
      "[09/12/2025-06:58:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 4 MiB, GPU 129 MiB\n",
      "[09/12/2025-06:58:52] [TRT] [I] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3514 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 371.3s, saved as 'models/land-seg.engine' (23.2 MB)\n",
      "\n",
      "Export complete (371.8s)\n",
      "Results saved to \u001b[1m/home/jetson/Documents/YOLO_tests/models\u001b[0m\n",
      "Predict:         yolo predict task=segment model=models/land-seg.engine imgsz=512 half \n",
      "Validate:        yolo val task=segment model=models/land-seg.engine imgsz=512 data=/home/projetopatron/Documents/mosa_weed_detection/datasets/landslide_dataset/data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/land-seg.engine'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = YOLO(\"models/land-seg.pt\")\n",
    "m.export(format=\"engine\", device=0, half=True, dynamic=False, nms=True)  # FP16 + estático + NMS no engine (quando suportado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecb34fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando necessidade de Exportar o Modelo\n",
      "\n",
      "Modelo Já exportado, pulando exportação.\n",
      "Aquecendo o modelo\n",
      "\n",
      "Loading /home/jetson/Documents/YOLO_tests/models/land-seg.engine for TensorRT inference...\n",
      "[09/12/2025-06:59:21] [TRT] [I] Loaded engine size: 23 MiB\n",
      "[09/12/2025-06:59:21] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +12, now: CPU 0, GPU 31 (MiB)\n",
      "Aquecimento concluído\n",
      "\n",
      "Iniciando Monitor_GPU\n",
      "Testando com 212 imagens!\n",
      "Ultralytics 8.3.161 🚀 Python-3.10.12 torch-2.5.0a0+872d972e41.nv24.08 CUDA:0 (Orin, 15656MiB)\n",
      "Loading /home/jetson/Documents/YOLO_tests/models/land-seg.engine for TensorRT inference...\n",
      "[09/12/2025-06:59:25] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "[09/12/2025-06:59:25] [TRT] [I] Loaded engine size: 23 MiB\n",
      "[09/12/2025-06:59:25] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +12, now: CPU 1, GPU 63 (MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1259.2±511.3 MB/s, size: 179.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jetson/Documents/YOLO_tests/dataset/landslide_dataset_1000/valid/labels.cache... 212 images, 0 backgrounds, 0 corrupt: 100%|██████████| 212/212 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 212/212 [00:03<00:00, 56.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        212       3029      0.954      0.953      0.987      0.969      0.928      0.902      0.952      0.636\n",
      "Speed: 0.7ms preprocess, 6.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A task é segment, métrica principal: metrics/mAP50-95(M)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from benchmark_PI import benchmark_PI\n",
    "results = benchmark_PI(model=\"models/land-seg.pt\", data=\"dataset/landslide_dataset_1000/data.yml\", imgsz=512, format='engine', device =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Format': 'TensorRT', 'Status❔': '✅', 'Size (MB)': 23.2, 'Inference Time(ms/im)': 6.66, 'Avarage Processing Time (ms/im)': 17.15, 'FPS': 58.32, 'Throughput (img/s)': 56.79, 'cpu_proc_avg (%)': 83.85, 'ram_proc_mb (MB)': 3163.9, 'gpu_avg (%)': 46.91, 'power_avg (W)': 0.0, 'ram_total_mb (MB)': 10244.0, 'metrics/mAP50-95(M)': 0.6357, 'metrics/precision(B)': 0.954, 'metrics/recall(B)': 0.9525, 'metrics/mAP50(B)': 0.9874, 'metrics/precision(M)': 0.9277, 'metrics/recall(M)': 0.9022, 'metrics/mAP50(M)': 0.9523}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
