{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)   # mostra todas as colunas\n",
    "pd.set_option(\"display.width\", None)         # evita quebra de linha\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)      # idem para linhas, se quiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28104a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Status❔</th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>Inference Time(ms/im)</th>\n",
       "      <th>Avarage Processing Time (ms/im)</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Throughput (img/s)</th>\n",
       "      <th>cpu_proc_avg (%)</th>\n",
       "      <th>ram_proc_mb (MB)</th>\n",
       "      <th>gpu_avg (%)</th>\n",
       "      <th>power_avg (W)</th>\n",
       "      <th>ram_total_mb (MB)</th>\n",
       "      <th>metrics/mAP50-95(M)</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/precision(M)</th>\n",
       "      <th>metrics/recall(M)</th>\n",
       "      <th>metrics/mAP50(M)</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TensorRT FP32</td>\n",
       "      <td>✅</td>\n",
       "      <td>40.8</td>\n",
       "      <td>10.94</td>\n",
       "      <td>22.78</td>\n",
       "      <td>43.90</td>\n",
       "      <td>43.14</td>\n",
       "      <td>69.62</td>\n",
       "      <td>993.2</td>\n",
       "      <td>56.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11682.3</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.9239</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>JetsonOrin16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TensorRT FP16</td>\n",
       "      <td>✅</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.66</td>\n",
       "      <td>16.57</td>\n",
       "      <td>60.34</td>\n",
       "      <td>58.75</td>\n",
       "      <td>58.32</td>\n",
       "      <td>2819.9</td>\n",
       "      <td>47.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13129.5</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>0.9543</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.9527</td>\n",
       "      <td>JetsonOrin16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ONNX</td>\n",
       "      <td>✅</td>\n",
       "      <td>38.7</td>\n",
       "      <td>144.71</td>\n",
       "      <td>173.12</td>\n",
       "      <td>5.78</td>\n",
       "      <td>5.76</td>\n",
       "      <td>465.39</td>\n",
       "      <td>2881.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12750.9</td>\n",
       "      <td>0.6176</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>JetsonOrin16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PyTorch</td>\n",
       "      <td>✅</td>\n",
       "      <td>19.6</td>\n",
       "      <td>22.77</td>\n",
       "      <td>34.57</td>\n",
       "      <td>28.93</td>\n",
       "      <td>28.55</td>\n",
       "      <td>85.72</td>\n",
       "      <td>2886.1</td>\n",
       "      <td>54.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12759.0</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>JetsonOrin16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ONNX</td>\n",
       "      <td>✅</td>\n",
       "      <td>38.6</td>\n",
       "      <td>94.25</td>\n",
       "      <td>140.94</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.08</td>\n",
       "      <td>652.07</td>\n",
       "      <td>619.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6626</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>NotebookAcer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PyTorch</td>\n",
       "      <td>✅</td>\n",
       "      <td>19.6</td>\n",
       "      <td>137.21</td>\n",
       "      <td>151.67</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.58</td>\n",
       "      <td>670.76</td>\n",
       "      <td>752.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>NotebookAcer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Format Status❔  Size (MB)  Inference Time(ms/im)  \\\n",
       "0  TensorRT FP32       ✅       40.8                  10.94   \n",
       "1  TensorRT FP16       ✅       23.4                   6.66   \n",
       "2           ONNX       ✅       38.7                 144.71   \n",
       "3        PyTorch       ✅       19.6                  22.77   \n",
       "4           ONNX       ✅       38.6                  94.25   \n",
       "5        PyTorch       ✅       19.6                 137.21   \n",
       "\n",
       "   Avarage Processing Time (ms/im)    FPS  Throughput (img/s)  \\\n",
       "0                            22.78  43.90               43.14   \n",
       "1                            16.57  60.34               58.75   \n",
       "2                           173.12   5.78                5.76   \n",
       "3                            34.57  28.93               28.55   \n",
       "4                           140.94   7.10                7.08   \n",
       "5                           151.67   6.59                6.58   \n",
       "\n",
       "   cpu_proc_avg (%)  ram_proc_mb (MB)  gpu_avg (%)  power_avg (W)  \\\n",
       "0             69.62             993.2        56.39            0.0   \n",
       "1             58.32            2819.9        47.82            0.0   \n",
       "2            465.39            2881.2         0.00            0.0   \n",
       "3             85.72            2886.1        54.59            0.0   \n",
       "4            652.07             619.5          NaN            NaN   \n",
       "5            670.76             752.8          NaN            NaN   \n",
       "\n",
       "   ram_total_mb (MB)  metrics/mAP50-95(M)  metrics/precision(B)  \\\n",
       "0            11682.3               0.5998                0.9548   \n",
       "1            13129.5               0.6363                0.9543   \n",
       "2            12750.9               0.6176                0.9537   \n",
       "3            12759.0               0.6295                0.9983   \n",
       "4                NaN               0.6626                0.9537   \n",
       "5                NaN               0.6939                0.9982   \n",
       "\n",
       "   metrics/recall(B)  metrics/mAP50(B)  metrics/precision(M)  \\\n",
       "0             0.9521            0.9884                0.9239   \n",
       "1             0.9525            0.9874                0.9274   \n",
       "2             0.9525            0.9874                0.9236   \n",
       "3             0.9917            0.9950                0.9421   \n",
       "4             0.9525            0.9884                0.9328   \n",
       "5             0.9917            0.9950                0.9559   \n",
       "\n",
       "   metrics/recall(M)  metrics/mAP50(M)          device  \n",
       "0             0.8980            0.9437  JetsonOrin16gb  \n",
       "1             0.9029            0.9527  JetsonOrin16gb  \n",
       "2             0.8976            0.9487  JetsonOrin16gb  \n",
       "3             0.9341            0.9570  JetsonOrin16gb  \n",
       "4             0.9127            0.9548    NotebookAcer  \n",
       "5             0.9475            0.9671    NotebookAcer  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bench_results.csv')\n",
    "df.head(10)\n",
    "\n",
    "#Verificar biblioteca para ESCALONADOR -> MANTER PROCESSO EM PRIORIDADE MÁXIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05998b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (8 CPUs, 15.3 GB RAM, 36.0/115.4 GB disk)\n",
      "\n",
      "Benchmarks complete for models/land-seg.pt on dataset/landslide_dataset_1000/data.yml at imgsz=512 (8.57s)\n",
      "Benchmarks legend:  - ✅ Success  - ❎ Export passed but validation failed  - ❌️ Export failed\n",
      "    Format Status❔  Size (MB)  metrics/mAP50-95(M)  Inference time (ms/im)    FPS\n",
      "0  PyTorch       ✅       19.6               0.6295                   24.78  40.35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.utils.benchmarks import benchmark\n",
    "from ultralytics import YOLO\n",
    "\n",
    "results_ultr = benchmark(model=f\"models/land-seg.pt\", data=\"dataset/landslide_dataset_1000/data.yml\", imgsz=512, format='-', device =0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (8 CPUs, 15.3 GB RAM, 36.0/115.4 GB disk)\n",
      "\n",
      "Benchmarks complete for models/land-seg.pt on dataset/landslide_dataset_1000/data.yml at imgsz=512 (284.69s)\n",
      "Benchmarks legend:  - ✅ Success  - ❎ Export passed but validation failed  - ❌️ Export failed\n",
      "     Format Status❔  Size (MB)  metrics/mAP50-95(M)  Inference time (ms/im)    FPS\n",
      "0  TensorRT       ✅       41.0               0.5998                   27.15  36.83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_ultr = benchmark(model=f\"models/land-seg.pt\", data=\"dataset/landslide_dataset_1000/data.yml\", imgsz=512, format='engine', device =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e16e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (8 CPUs, 15.3 GB RAM, 36.0/115.4 GB disk)\n",
      "\n",
      "Benchmarks complete for models/land-seg.pt on dataset/landslide_dataset_1000/data.yml at imgsz=512 (43.07s)\n",
      "Benchmarks legend:  - ✅ Success  - ❎ Export passed but validation failed  - ❌️ Export failed\n",
      "  Format Status❔  Size (MB)  metrics/mAP50-95(M)  Inference time (ms/im)  FPS\n",
      "0   ONNX       ✅       38.6               0.5998                  153.89  6.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_ultr = benchmark(model=f\"models/land-seg.pt\", data=\"dataset/landslide_dataset_1000/data.yml\", imgsz=512, format='onnx', device =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "770be9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.161 🚀 Python-3.10.12 torch-2.5.0a0+872d972e41.nv24.08 CUDA:0 (Orin, 15656MiB)\n",
      "YOLO11s-seg summary (fused): 113 layers, 10,067,203 parameters, 0 gradients, 35.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'models/land-seg.pt' with input shape (1, 3, 512, 512) BCHW and output shape(s) ((1, 300, 38), (1, 32, 128, 128)) (19.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.58...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 3.9s, saved as 'models/land-seg.onnx' (38.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.3.0...\n",
      "[09/12/2025-06:52:45] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 1516, GPU 9207 (MiB)\n",
      "[09/12/2025-06:52:46] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +926, GPU +711, now: CPU 2442, GPU 9918 (MiB)\n",
      "[09/12/2025-06:52:46] [TRT] [I] ----------------------------------------------------------------\n",
      "[09/12/2025-06:52:46] [TRT] [I] Input filename:   models/land-seg.onnx\n",
      "[09/12/2025-06:52:46] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[09/12/2025-06:52:46] [TRT] [I] Opset version:    19\n",
      "[09/12/2025-06:52:46] [TRT] [I] Producer name:    pytorch\n",
      "[09/12/2025-06:52:46] [TRT] [I] Producer version: 2.5.0\n",
      "[09/12/2025-06:52:46] [TRT] [I] Domain:           \n",
      "[09/12/2025-06:52:46] [TRT] [I] Model version:    0\n",
      "[09/12/2025-06:52:46] [TRT] [I] Doc string:       \n",
      "[09/12/2025-06:52:46] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 512, 512) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 300, 38) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(1, 32, 128, 128) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as models/land-seg.engine\n",
      "[09/12/2025-06:52:46] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[09/12/2025-06:58:46] [TRT] [I] Detected 1 inputs and 2 output network tensors.\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Host Persistent Memory: 587504\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Device Persistent Memory: 69120\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Scratch Memory: 1179648\n",
      "[09/12/2025-06:58:51] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 193 steps to complete.\n",
      "[09/12/2025-06:58:51] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 26.6743ms to assign 13 blocks to 193 nodes requiring 13108224 bytes.\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Activation Memory: 13107200\n",
      "[09/12/2025-06:58:51] [TRT] [I] Total Weights Memory: 20248896\n",
      "[09/12/2025-06:58:52] [TRT] [I] Engine generation completed in 365.087 seconds.\n",
      "[09/12/2025-06:58:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 4 MiB, GPU 129 MiB\n",
      "[09/12/2025-06:58:52] [TRT] [I] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3514 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 371.3s, saved as 'models/land-seg.engine' (23.2 MB)\n",
      "\n",
      "Export complete (371.8s)\n",
      "Results saved to \u001b[1m/home/jetson/Documents/YOLO_tests/models\u001b[0m\n",
      "Predict:         yolo predict task=segment model=models/land-seg.engine imgsz=512 half \n",
      "Validate:        yolo val task=segment model=models/land-seg.engine imgsz=512 data=/home/projetopatron/Documents/mosa_weed_detection/datasets/landslide_dataset/data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/land-seg.engine'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = YOLO(\"models/land-seg.pt\")\n",
    "m.export(format=\"engine\", device=0, half=True, dynamic=False, nms=True)  # FP16 + estático + NMS no engine (quando suportado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecb34fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando necessidade de Exportar o Modelo\n",
      "\n",
      "Modelo Já exportado, pulando exportação.\n",
      "Aquecendo o modelo\n",
      "\n",
      "Loading /home/jetson/Documents/YOLO_tests/models/land-seg.engine for TensorRT inference...\n",
      "[09/12/2025-06:59:21] [TRT] [I] Loaded engine size: 23 MiB\n",
      "[09/12/2025-06:59:21] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +12, now: CPU 0, GPU 31 (MiB)\n",
      "Aquecimento concluído\n",
      "\n",
      "Iniciando Monitor_GPU\n",
      "Testando com 212 imagens!\n",
      "Ultralytics 8.3.161 🚀 Python-3.10.12 torch-2.5.0a0+872d972e41.nv24.08 CUDA:0 (Orin, 15656MiB)\n",
      "Loading /home/jetson/Documents/YOLO_tests/models/land-seg.engine for TensorRT inference...\n",
      "[09/12/2025-06:59:25] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "[09/12/2025-06:59:25] [TRT] [I] Loaded engine size: 23 MiB\n",
      "[09/12/2025-06:59:25] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +12, now: CPU 1, GPU 63 (MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1259.2±511.3 MB/s, size: 179.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jetson/Documents/YOLO_tests/dataset/landslide_dataset_1000/valid/labels.cache... 212 images, 0 backgrounds, 0 corrupt: 100%|██████████| 212/212 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 212/212 [00:03<00:00, 56.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        212       3029      0.954      0.953      0.987      0.969      0.928      0.902      0.952      0.636\n",
      "Speed: 0.7ms preprocess, 6.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A task é segment, métrica principal: metrics/mAP50-95(M)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from benchmark_PI import benchmark_PI\n",
    "results = benchmark_PI(model=\"models/land-seg.pt\", data=\"dataset/landslide_dataset_1000/data.yml\", imgsz=512, format='engine', device =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Format': 'TensorRT', 'Status❔': '✅', 'Size (MB)': 23.2, 'Inference Time(ms/im)': 6.66, 'Avarage Processing Time (ms/im)': 17.15, 'FPS': 58.32, 'Throughput (img/s)': 56.79, 'cpu_proc_avg (%)': 83.85, 'ram_proc_mb (MB)': 3163.9, 'gpu_avg (%)': 46.91, 'power_avg (W)': 0.0, 'ram_total_mb (MB)': 10244.0, 'metrics/mAP50-95(M)': 0.6357, 'metrics/precision(B)': 0.954, 'metrics/recall(B)': 0.9525, 'metrics/mAP50(B)': 0.9874, 'metrics/precision(M)': 0.9277, 'metrics/recall(M)': 0.9022, 'metrics/mAP50(M)': 0.9523}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
